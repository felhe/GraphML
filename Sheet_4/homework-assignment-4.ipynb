{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22db94a9-2dbf-4a38-b51f-0fe5540f0198",
   "metadata": {},
   "source": [
    "# 1) PyTorch Geometric (Datasets and Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78850834-e022-45e1-a84d-552da2d54ccc",
   "metadata": {},
   "source": [
    "PyTorch Geometric has two classes for storing and/or transforming graphs into tensor format. One is `torch_geometric.datasets`, which contains a variety of common graph datasets. Another is `torch_geometric.data`, which provides the data handling of graphs in PyTorch tensors.\n",
    "\n",
    "In this section, we will learn how to use `torch_geometric.datasets` and `torch_geometric.data` together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c706a63-5404-4fe8-a4f3-3869ecfd79e1",
   "metadata": {},
   "source": [
    "## PyG Datasets\n",
    "\n",
    "The `torch_geometric.datasets` class has many common graph datasets. Here we will explore its usage through one example dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "a540a4de-bc7f-4ed5-a4e3-78d2a64a42f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:46:58.159761Z",
     "start_time": "2024-06-16T21:46:58.141241Z"
    }
   },
   "source": [
    "import torch_geometric.nn\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "root = 'enzymes'\n",
    "name = 'ENZYMES'\n",
    "\n",
    "# The ENZYMES dataset\n",
    "pyg_dataset = TUDataset(root, name)\n",
    "\n",
    "# You will find that there are 600 graphs in this dataset\n",
    "print(pyg_dataset)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES(600)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "fcb72de7-4c91-46f7-bea1-4795d92c2164",
   "metadata": {},
   "source": [
    "## Question 1: What is the number of classes and number of features in the ENZYMES dataset?"
   ]
  },
  {
   "cell_type": "code",
   "id": "6699d9f9-cf0e-465c-82b1-2ec724c97a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:46:58.354241Z",
     "start_time": "2024-06-16T21:46:58.344264Z"
    }
   },
   "source": [
    "# TODO: Implement a function that takes a PyG dataset object\n",
    "# and returns the number of classes for that dataset.\n",
    "def get_num_classes(pyg_dataset):\n",
    "    num_classes = pyg_dataset.num_classes\n",
    "\n",
    "    return num_classes\n",
    "\n",
    "\n",
    "# TODO: Implement a function that takes a PyG dataset object\n",
    "# and returns the number of features for that dataset.\n",
    "def get_num_features(pyg_dataset):\n",
    "    num_features = pyg_dataset.num_features\n",
    "\n",
    "    return num_features\n",
    "\n",
    "\n",
    "num_classes = get_num_classes(pyg_dataset)\n",
    "num_features = get_num_features(pyg_dataset)\n",
    "print(\"{} dataset has {} classes\".format(name, num_classes))\n",
    "print(\"{} dataset has {} features\".format(name, num_features))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES dataset has 6 classes\n",
      "ENZYMES dataset has 3 features\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "00e3edeb-dfea-464f-a58b-9596f06ff05d",
   "metadata": {},
   "source": [
    "### Answer 1:\n",
    "\n",
    "ENZYMES dataset has 6 classes\n",
    "\n",
    "ENZYMES dataset has 3 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075ab6d-efb6-4301-b741-063a96ef3aaf",
   "metadata": {},
   "source": [
    "## PyG Data\n",
    "\n",
    "Each PyG dataset stores a list of `torch_geometric.data.Data` objects, where each `torch_geometric.data.Data` object represents a graph. We can easily get the `Data` object by indexing into the dataset.\n",
    "\n",
    "For more information such as what is stored in the `Data` object, please refer to the [documentation](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b92190-ada3-4fe1-a40d-bf99c797bfb0",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2: What is the label of the graph with index 100 in the ENZYMES dataset?"
   ]
  },
  {
   "cell_type": "code",
   "id": "75b2b148-3202-48ea-872b-bbb69300fa3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:46:58.406951Z",
     "start_time": "2024-06-16T21:46:58.399407Z"
    }
   },
   "source": [
    "# TODO: Implement a function that takes a PyG dataset object,\n",
    "# an index of a graph within the dataset, and returns the class/label\n",
    "# of the graph (as an integer).\n",
    "def get_graph_class(pyg_dataset, idx):\n",
    "    graph = pyg_dataset[idx]\n",
    "    label = int(graph.y)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "# Here pyg_dataset is a dataset for graph classification\n",
    "graph_0 = pyg_dataset[0]\n",
    "idx = 100\n",
    "label = get_graph_class(pyg_dataset, idx)\n",
    "print('Graph with index {} has label {}'.format(idx, label))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with index 100 has label 4\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "3ac24735-67dd-4c3f-b83e-407264a140ca",
   "metadata": {},
   "source": [
    "### Answer 2:\n",
    "\n",
    "Graph with index 100 has label 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3fac81-4086-44c4-906b-ff11300cb986",
   "metadata": {},
   "source": [
    "## Question 3: How many edges does the graph with index 200 have?"
   ]
  },
  {
   "cell_type": "code",
   "id": "be5931d8-7474-4b9f-a491-4f1c0455f5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:46:58.496639Z",
     "start_time": "2024-06-16T21:46:58.479258Z"
    }
   },
   "source": [
    "# TODO: Implement a function that takes a PyG dataset object,\n",
    "# the index of a graph in the dataset, and returns the number of\n",
    "# edges in the graph (as an integer). You should not count an edge\n",
    "# twice if the graph is undirected. For example, in an undirected\n",
    "# graph G, if two nodes v and u are connected by an edge, this edge\n",
    "# should only be counted once.\n",
    "def get_graph_num_edges(pyg_dataset, idx):\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. You can't return the data.num_edges directly\n",
    "    ## 2. We assume the graph is undirected\n",
    "    ## 3. Look at the PyG dataset built in functions\n",
    "    from torch_geometric.data import Data\n",
    "    graph: Data = pyg_dataset[idx]\n",
    "    num_edges = graph.num_edges if graph.is_directed() else graph.num_edges / 2\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return int(num_edges)\n",
    "\n",
    "\n",
    "idx = 200\n",
    "num_edges = get_graph_num_edges(pyg_dataset, idx)\n",
    "print('Graph with index {} has {} edges'.format(idx, num_edges))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with index 200 has 53 edges\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "150697e1-963c-4488-bc12-6c2e13b3bbb6",
   "metadata": {},
   "source": [
    "### Answer 3:\n",
    "\n",
    "Graph with index 200 has 53 edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a606e8e-c7c5-4a82-b693-b74b6536148d",
   "metadata": {},
   "source": [
    "# 2) Open Graph Benchmark (OGB)\n",
    "\n",
    "The Open Graph Benchmark (OGB) is a collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs. Its datasets are automatically downloaded, processed, and split using the OGB Data Loader. The model performance can then be evaluated by using the OGB Evaluator in a unified manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbd178-5043-441f-8cce-f6a2820f0b70",
   "metadata": {},
   "source": [
    "## Dataset and Data\n",
    "\n",
    "OGB also supports PyG dataset and data classes. Here we take a look on the `ogbn-arxiv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "5316caac-6394-47c5-8623-d753cbbd04af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:48:36.027831Z",
     "start_time": "2024-06-16T21:48:18.890123Z"
    }
   },
   "source": [
    "from torch_geometric.utils import to_edge_index\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "dataset_name = 'ogbn-arxiv'\n",
    "# Load the dataset and transform it to sparse tensor\n",
    "dataset = PygNodePropPredDataset(name=dataset_name, transform=T.ToSparseTensor())\n",
    "print('The {} dataset has {} graph'.format(dataset_name, len(dataset)))\n",
    "\n",
    "# Extract the graph\n",
    "data = dataset[0]\n",
    "\n",
    "# create missing edge index\n",
    "data.edge_index, _ = to_edge_index(data.adj_t)\n",
    "print(data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ogbn-arxiv dataset has 1 graph\n",
      "Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343], edge_index=[2, 1166243])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "bf1ed0e8-b65c-45a9-ba4e-05fe39f6d1b4",
   "metadata": {},
   "source": [
    "## Question 4: How many features are in the ogbn-arxiv graph?"
   ]
  },
  {
   "cell_type": "code",
   "id": "78480801-f874-4645-99a3-ab7c45028d8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:47:00.918249Z",
     "start_time": "2024-06-16T21:47:00.908345Z"
    }
   },
   "source": [
    "# TODO: Implement a function that takes a PyG data object,\n",
    "# and returns the number of features in the graph (as an integer).\n",
    "def graph_num_features(data):\n",
    "    ############# Your code here ############\n",
    "    num_features = data.num_features\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return int(num_features)\n",
    "\n",
    "\n",
    "num_features = graph_num_features(data)\n",
    "print('The graph has {} features'.format(num_features))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The graph has 128 features\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "addbe6f5-53bf-44d9-b640-caafb22e604a",
   "metadata": {},
   "source": [
    "### Answer 4:\n",
    "\n",
    "The graph has 128 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b562c3-e4bc-416c-836e-a6dc7959bb9b",
   "metadata": {},
   "source": [
    "# 3) GNN: Node Property Prediction\n",
    "\n",
    "In this section we will build our first graph neural network using PyTorch Geometric. Then we will apply it to the task of node property prediction (node classification).\n",
    "\n",
    "Specifically, we will use GCN as the foundation for your graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer."
   ]
  },
  {
   "cell_type": "code",
   "id": "314c2860-37a8-4f00-9fd1-a30b1b56de56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:47:00.934524Z",
     "start_time": "2024-06-16T21:47:00.920115Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "# The PyG built-in GCNConv\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "090874a3-9673-4e6c-b1d9-76a4b19083d5",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "f7284f26-5530-4eee-8fc1-1d8cef997af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:47:01.828783Z",
     "start_time": "2024-06-16T21:47:00.937859Z"
    }
   },
   "source": [
    "# Add a transform that creates the graph and directly transforms it to be undirected\n",
    "dataset_name = 'ogbn-arxiv'\n",
    "dataset = PygNodePropPredDataset(name=dataset_name, transform=T.Compose([T.ToUndirected(), T.ToSparseTensor()]))\n",
    "data = dataset[0]\n",
    "print(data)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If you use GPU, the device should be cuda\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "data = data.to(device)\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx = split_idx['train'].to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(num_nodes=169343, x=[169343, 128], node_year=[169343, 1], y=[169343, 1], adj_t=[169343, 169343])\n",
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "attachments": {
    "752b2d4e-b586-4f0c-af18-ed95814266f3.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5AAAABdCAYAAADT0onTAAAG63RFWHRteGZpbGUAJTNDbXhmaWxl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\nx5aydioAAAAASUVORK5CYII=\n"
    }
   },
   "cell_type": "markdown",
   "id": "be4a547c-e68a-4329-8d71-a469cda3a804",
   "metadata": {},
   "source": [
    "## GCN Model\n",
    "\n",
    "Now we will implement our GCN model!\n",
    "\n",
    "Please follow the figure below to implement the `forward` function.\n",
    "\n",
    "![gcnconv.png](gcnconv.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "0960d222-d014-4ddd-b472-a81b28b79152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:47:01.836689Z",
     "start_time": "2024-06-16T21:47:01.831678Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1592c443-2bfd-4414-9e22-df9bb967dc8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:47:01.855625Z",
     "start_time": "2024-06-16T21:47:01.840075Z"
    }
   },
   "source": [
    "from torch.nn import BatchNorm1d\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    # TODO: Implement a function that initializes self.convs,\n",
    "    # self.bns, and self.softmax.\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
    "                 dropout, return_embeds=False):\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 0. Add a sanity check concerning the number of layers\n",
    "        ## 1. You should use torch.nn.ModuleList for self.convs and self.bns\n",
    "        ## 2. self.convs has num_layers GCNConv layers\n",
    "        ## 3. self.bns has num_layers - 1 BatchNorm1d layers\n",
    "        ## 4. You should use torch.nn.LogSoftmax for self.softmax\n",
    "        ## 5. The parameters you can set for GCNConv include 'in_channels' and\n",
    "        ## 'out_channels'. For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv\n",
    "        ## 6. The only parameter you need to set for BatchNorm1d is 'num_features'\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html\n",
    "\n",
    "        # A list of GCNConv layers\n",
    "        self.convs = torch.nn.ModuleList([GCNConv(input_dim, hidden_dim)])\n",
    "        self.convs = self.convs.extend([GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers - 2)])\n",
    "        self.convs = self.convs.append(GCNConv(hidden_dim, output_dim))\n",
    "\n",
    "        # A list of 1D batch normalization layers\n",
    "        self.bns = torch.nn.ModuleList([BatchNorm1d(hidden_dim) for _ in range(num_layers - 1)])\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = torch.nn.LogSoftmax()\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        # Probability of an element getting zeroed\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Skip classification layer and return node embeddings\n",
    "        self.return_embeds = return_embeds\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    # TODO: Implement a function that takes the feature tensor x and\n",
    "    # edge_index tensor adj_t and returns the output tensor as\n",
    "    # shown in the figure.\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct the network as shown in the figure\n",
    "        ## 2. torch.nn.functional.relu and torch.nn.functional.dropout are useful\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch.org/docs/stable/nn.functional.html\n",
    "        ## 3. Don't forget to set F.dropout training to self.training\n",
    "        ## 4. If return_embeds is True, then skip the last softmax layer\n",
    "\n",
    "        for i, conv in enumerate(self.bns):\n",
    "            conv_out = self.convs[i](x, edge_index)\n",
    "            norm = self.bns[i](conv_out)\n",
    "            x = F.relu(norm)\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "        \n",
    "        if self.return_embeds:\n",
    "            out = x\n",
    "        else:\n",
    "            out = self.convs[-1](x, edge_index)\n",
    "            out = self.softmax(out)\n",
    "        \n",
    "        #########################################\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "8a6292c8-b790-48ae-b63d-87a216c8bf0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:59:39.704502Z",
     "start_time": "2024-06-16T21:59:39.686864Z"
    }
   },
   "source": [
    "# TODO: Implement a function that trains the model by\n",
    "# using the given optimizer and loss_fn.\n",
    "def train(model, data, train_idx, optimizer, loss_fn):\n",
    "    model.train()\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. Zero grad the optimizer\n",
    "    ## 2. Feed the data into the model\n",
    "    ## 3. Slice the model output and label by train_idx\n",
    "    ## 4. Feed the sliced output and label to loss_fn\n",
    "\n",
    "    #########################################\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out = model.forward(data.x, data.edge_index)\n",
    "    out = out[train_idx]\n",
    "    loss = loss_fn(out, data.y[train_idx].flatten(start_dim=0))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "fc775b72-726c-496c-b5f2-70fac0467b02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:47:01.886434Z",
     "start_time": "2024-06-16T21:47:01.875962Z"
    }
   },
   "source": [
    "# TODO: Implement a function that tests the model by\n",
    "# using the given split_idx and evaluator.\n",
    "@torch.no_grad()\n",
    "def test(model, data, split_idx, evaluator, save_model_results=False):\n",
    "    model.eval()\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note:\n",
    "    ## 1. No index slicing here\n",
    "    out = model.forward(data.x, data.edge_index)\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']],\n",
    "    })['acc']\n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']],\n",
    "    })['acc']\n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': data.y[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']],\n",
    "    })['acc']\n",
    "\n",
    "    if save_model_results:\n",
    "        print(\"Saving Model Predictions\")\n",
    "\n",
    "        data = {}\n",
    "        data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
    "\n",
    "        df = pd.DataFrame(data=data)\n",
    "        # Save locally as csv\n",
    "        df.to_csv('ogbn-arxiv_node.csv', sep=',', index=False)\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "5e8878a1-0b12-459b-83fd-ad538bd0885b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:47:01.908835Z",
     "start_time": "2024-06-16T21:47:01.889455Z"
    }
   },
   "source": [
    "# Please do not change the args\n",
    "args = {\n",
    "    'device': device,\n",
    "    'num_layers': 3,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.01,\n",
    "    'epochs': 100,\n",
    "}\n",
    "args"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cpu',\n",
       " 'num_layers': 3,\n",
       " 'hidden_dim': 256,\n",
       " 'dropout': 0.5,\n",
       " 'lr': 0.01,\n",
       " 'epochs': 100}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "743d4916-3421-4512-9cb8-ab5d090bfe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T21:47:08.060192Z",
     "start_time": "2024-06-16T21:47:07.937203Z"
    }
   },
   "source": [
    "model = GCN(data.num_features, args['hidden_dim'],\n",
    "            dataset.num_classes, args['num_layers'],\n",
    "            args['dropout']).to(device)\n",
    "evaluator = Evaluator(name='ogbn-arxiv')\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "37851c7b-57b0-4ed8-8baa-5193a066c39d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:28:09.880539Z",
     "start_time": "2024-06-16T21:59:45.111056Z"
    }
   },
   "source": [
    "# Please do not change these args\n",
    "# Training should take <10min using GPU runtime\n",
    "import copy\n",
    "\n",
    "# reset the parameters to initial random value\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "loss_fn = F.nll_loss\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    loss = train(model, data, train_idx, optimizer, loss_fn)\n",
    "    result = test(model, data, split_idx, evaluator)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * valid_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 4.3184, Train: 19.43%, Valid: 25.94% Test: 23.52%\n",
      "Epoch: 02, Loss: 2.7521, Train: 28.27%, Valid: 24.89% Test: 30.07%\n",
      "Epoch: 03, Loss: 2.3539, Train: 21.22%, Valid: 12.35% Test: 11.46%\n",
      "Epoch: 04, Loss: 2.1698, Train: 21.25%, Valid: 9.79% Test: 7.50%\n",
      "Epoch: 05, Loss: 2.0258, Train: 24.61%, Valid: 13.32% Test: 10.78%\n",
      "Epoch: 06, Loss: 1.9567, Train: 31.12%, Valid: 22.46% Test: 22.24%\n",
      "Epoch: 07, Loss: 1.8899, Train: 37.81%, Valid: 32.83% Test: 35.41%\n",
      "Epoch: 08, Loss: 1.8220, Train: 41.71%, Valid: 38.76% Test: 42.35%\n",
      "Epoch: 09, Loss: 1.7856, Train: 43.04%, Valid: 41.11% Test: 44.74%\n",
      "Epoch: 10, Loss: 1.7517, Train: 43.47%, Valid: 42.13% Test: 45.90%\n",
      "Epoch: 11, Loss: 1.7176, Train: 44.27%, Valid: 44.23% Test: 48.10%\n",
      "Epoch: 12, Loss: 1.7054, Train: 44.57%, Valid: 44.79% Test: 48.32%\n",
      "Epoch: 13, Loss: 1.6819, Train: 45.53%, Valid: 45.66% Test: 48.83%\n",
      "Epoch: 14, Loss: 1.6543, Train: 46.72%, Valid: 46.42% Test: 49.36%\n",
      "Epoch: 15, Loss: 1.6385, Train: 47.82%, Valid: 46.90% Test: 49.85%\n",
      "Epoch: 16, Loss: 1.6293, Train: 49.08%, Valid: 48.29% Test: 51.53%\n",
      "Epoch: 17, Loss: 1.6031, Train: 50.73%, Valid: 50.58% Test: 54.09%\n",
      "Epoch: 18, Loss: 1.6015, Train: 51.89%, Valid: 52.27% Test: 55.84%\n",
      "Epoch: 19, Loss: 1.5876, Train: 52.73%, Valid: 53.53% Test: 56.96%\n",
      "Epoch: 20, Loss: 1.5738, Train: 53.29%, Valid: 54.48% Test: 57.81%\n",
      "Epoch: 21, Loss: 1.5551, Train: 54.12%, Valid: 55.88% Test: 59.01%\n",
      "Epoch: 22, Loss: 1.5543, Train: 55.35%, Valid: 57.79% Test: 60.69%\n",
      "Epoch: 23, Loss: 1.5450, Train: 56.65%, Valid: 59.66% Test: 61.95%\n",
      "Epoch: 24, Loss: 1.5327, Train: 57.57%, Valid: 60.14% Test: 62.21%\n",
      "Epoch: 25, Loss: 1.5231, Train: 58.06%, Valid: 60.71% Test: 62.58%\n",
      "Epoch: 26, Loss: 1.5159, Train: 58.31%, Valid: 60.80% Test: 63.01%\n",
      "Epoch: 27, Loss: 1.5052, Train: 58.50%, Valid: 60.83% Test: 63.09%\n",
      "Epoch: 28, Loss: 1.4901, Train: 58.75%, Valid: 60.63% Test: 63.20%\n",
      "Epoch: 29, Loss: 1.4881, Train: 58.90%, Valid: 60.32% Test: 63.09%\n",
      "Epoch: 30, Loss: 1.4873, Train: 59.32%, Valid: 60.76% Test: 63.49%\n",
      "Epoch: 31, Loss: 1.4738, Train: 59.93%, Valid: 61.73% Test: 64.08%\n",
      "Epoch: 32, Loss: 1.4697, Train: 60.43%, Valid: 62.16% Test: 64.02%\n",
      "Epoch: 33, Loss: 1.4680, Train: 60.84%, Valid: 62.36% Test: 63.83%\n",
      "Epoch: 34, Loss: 1.4573, Train: 61.18%, Valid: 62.51% Test: 63.62%\n",
      "Epoch: 35, Loss: 1.4508, Train: 61.37%, Valid: 62.57% Test: 63.52%\n",
      "Epoch: 36, Loss: 1.4476, Train: 61.49%, Valid: 62.65% Test: 63.37%\n",
      "Epoch: 37, Loss: 1.4406, Train: 61.66%, Valid: 62.93% Test: 63.68%\n",
      "Epoch: 38, Loss: 1.4346, Train: 61.88%, Valid: 63.10% Test: 63.75%\n",
      "Epoch: 39, Loss: 1.4280, Train: 62.10%, Valid: 63.21% Test: 64.07%\n",
      "Epoch: 40, Loss: 1.4295, Train: 62.31%, Valid: 63.21% Test: 64.12%\n",
      "Epoch: 41, Loss: 1.4222, Train: 62.35%, Valid: 62.90% Test: 64.12%\n",
      "Epoch: 42, Loss: 1.4156, Train: 62.38%, Valid: 62.76% Test: 64.06%\n",
      "Epoch: 43, Loss: 1.4117, Train: 62.51%, Valid: 62.96% Test: 64.17%\n",
      "Epoch: 44, Loss: 1.4064, Train: 62.83%, Valid: 63.45% Test: 64.58%\n",
      "Epoch: 45, Loss: 1.4031, Train: 63.09%, Valid: 63.74% Test: 64.87%\n",
      "Epoch: 46, Loss: 1.4007, Train: 63.17%, Valid: 63.81% Test: 64.80%\n",
      "Epoch: 47, Loss: 1.3994, Train: 63.19%, Valid: 63.86% Test: 64.84%\n",
      "Epoch: 48, Loss: 1.3942, Train: 63.24%, Valid: 63.84% Test: 64.72%\n",
      "Epoch: 49, Loss: 1.3906, Train: 63.13%, Valid: 63.31% Test: 64.11%\n",
      "Epoch: 50, Loss: 1.3897, Train: 62.99%, Valid: 62.73% Test: 63.19%\n",
      "Epoch: 51, Loss: 1.3813, Train: 63.17%, Valid: 62.81% Test: 63.57%\n",
      "Epoch: 52, Loss: 1.3805, Train: 63.46%, Valid: 63.36% Test: 64.55%\n",
      "Epoch: 53, Loss: 1.3778, Train: 63.67%, Valid: 63.77% Test: 65.11%\n",
      "Epoch: 54, Loss: 1.3742, Train: 63.76%, Valid: 63.99% Test: 65.39%\n",
      "Epoch: 55, Loss: 1.3726, Train: 63.86%, Valid: 64.15% Test: 65.46%\n",
      "Epoch: 56, Loss: 1.3663, Train: 63.95%, Valid: 64.22% Test: 65.37%\n",
      "Epoch: 57, Loss: 1.3654, Train: 64.01%, Valid: 64.13% Test: 65.23%\n",
      "Epoch: 58, Loss: 1.3627, Train: 64.08%, Valid: 64.33% Test: 65.44%\n",
      "Epoch: 59, Loss: 1.3578, Train: 64.12%, Valid: 64.33% Test: 65.45%\n",
      "Epoch: 60, Loss: 1.3587, Train: 64.08%, Valid: 63.74% Test: 64.73%\n",
      "Epoch: 61, Loss: 1.3537, Train: 63.96%, Valid: 63.20% Test: 63.75%\n",
      "Epoch: 62, Loss: 1.3515, Train: 64.11%, Valid: 63.36% Test: 64.11%\n",
      "Epoch: 63, Loss: 1.3472, Train: 64.39%, Valid: 64.14% Test: 65.31%\n",
      "Epoch: 64, Loss: 1.3457, Train: 64.49%, Valid: 64.56% Test: 66.05%\n",
      "Epoch: 65, Loss: 1.3425, Train: 64.58%, Valid: 64.71% Test: 66.17%\n",
      "Epoch: 66, Loss: 1.3399, Train: 64.57%, Valid: 64.71% Test: 66.23%\n",
      "Epoch: 67, Loss: 1.3342, Train: 64.61%, Valid: 64.73% Test: 66.15%\n",
      "Epoch: 68, Loss: 1.3330, Train: 64.73%, Valid: 64.69% Test: 66.17%\n",
      "Epoch: 69, Loss: 1.3354, Train: 64.94%, Valid: 64.76% Test: 66.15%\n",
      "Epoch: 70, Loss: 1.3277, Train: 64.96%, Valid: 64.53% Test: 65.73%\n",
      "Epoch: 71, Loss: 1.3244, Train: 64.85%, Valid: 63.99% Test: 64.92%\n",
      "Epoch: 72, Loss: 1.3255, Train: 64.83%, Valid: 63.89% Test: 64.66%\n",
      "Epoch: 73, Loss: 1.3239, Train: 64.96%, Valid: 64.20% Test: 64.84%\n",
      "Epoch: 74, Loss: 1.3177, Train: 65.01%, Valid: 64.27% Test: 65.21%\n",
      "Epoch: 75, Loss: 1.3159, Train: 65.06%, Valid: 64.59% Test: 65.53%\n",
      "Epoch: 76, Loss: 1.3175, Train: 65.20%, Valid: 64.76% Test: 65.91%\n",
      "Epoch: 77, Loss: 1.3134, Train: 65.27%, Valid: 64.75% Test: 65.93%\n",
      "Epoch: 78, Loss: 1.3108, Train: 65.39%, Valid: 64.79% Test: 65.96%\n",
      "Epoch: 79, Loss: 1.3087, Train: 65.55%, Valid: 64.57% Test: 65.32%\n",
      "Epoch: 80, Loss: 1.3100, Train: 65.50%, Valid: 64.18% Test: 64.44%\n",
      "Epoch: 81, Loss: 1.3107, Train: 65.58%, Valid: 64.14% Test: 64.30%\n",
      "Epoch: 82, Loss: 1.3046, Train: 65.74%, Valid: 64.36% Test: 64.75%\n",
      "Epoch: 83, Loss: 1.2991, Train: 65.90%, Valid: 64.90% Test: 65.81%\n",
      "Epoch: 84, Loss: 1.3044, Train: 65.98%, Valid: 65.21% Test: 66.73%\n",
      "Epoch: 85, Loss: 1.2978, Train: 65.93%, Valid: 65.16% Test: 66.79%\n",
      "Epoch: 86, Loss: 1.2930, Train: 65.99%, Valid: 65.22% Test: 66.88%\n",
      "Epoch: 87, Loss: 1.2926, Train: 65.95%, Valid: 65.26% Test: 66.49%\n",
      "Epoch: 88, Loss: 1.2924, Train: 65.95%, Valid: 64.99% Test: 66.06%\n",
      "Epoch: 89, Loss: 1.2858, Train: 65.97%, Valid: 65.11% Test: 66.07%\n",
      "Epoch: 90, Loss: 1.2925, Train: 66.03%, Valid: 65.22% Test: 66.12%\n",
      "Epoch: 91, Loss: 1.2857, Train: 66.05%, Valid: 65.27% Test: 66.52%\n",
      "Epoch: 92, Loss: 1.2852, Train: 65.95%, Valid: 65.20% Test: 66.76%\n",
      "Epoch: 93, Loss: 1.2830, Train: 66.03%, Valid: 65.19% Test: 66.99%\n",
      "Epoch: 94, Loss: 1.2832, Train: 66.06%, Valid: 65.08% Test: 66.59%\n",
      "Epoch: 95, Loss: 1.2780, Train: 66.11%, Valid: 64.79% Test: 66.04%\n",
      "Epoch: 96, Loss: 1.2793, Train: 66.32%, Valid: 65.13% Test: 66.24%\n",
      "Epoch: 97, Loss: 1.2737, Train: 66.45%, Valid: 65.56% Test: 66.75%\n",
      "Epoch: 98, Loss: 1.2675, Train: 66.53%, Valid: 65.61% Test: 66.43%\n",
      "Epoch: 99, Loss: 1.2678, Train: 66.56%, Valid: 65.38% Test: 66.21%\n",
      "Epoch: 100, Loss: 1.2737, Train: 66.51%, Valid: 65.34% Test: 66.41%\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "fa4def01-b971-4b42-8098-c27ba5f70760",
   "metadata": {},
   "source": [
    "## Question 5: What are your `best_model` validation and test accuracies?\n",
    "\n",
    "Run the cell below to see the results of your best of model. Mark the results."
   ]
  },
  {
   "cell_type": "code",
   "id": "037078f8-b438-4571-b9b7-d16fc484a6ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:37:17.076136Z",
     "start_time": "2024-06-16T22:37:12.041411Z"
    }
   },
   "source": [
    "best_result = test(best_model, data, split_idx, evaluator, save_model_results=False)\n",
    "train_acc, valid_acc, test_acc = best_result\n",
    "print(f'Best model: '\n",
    "      f'Train: {100 * train_acc:.2f}%, '\n",
    "      f'Valid: {100 * valid_acc:.2f}% '\n",
    "      f'Test: {100 * test_acc:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: Train: 66.53%, Valid: 65.61% Test: 66.43%\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "36234101-6d38-4e85-9ee8-ee7be616848a",
   "metadata": {},
   "source": [
    "### Answer 5: \n",
    "\n",
    "Best model: Train: 66.53%, Valid: 65.61% Test: 66.43%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67645ad4-aba0-4aba-a616-5d1e10cf20a4",
   "metadata": {},
   "source": [
    "## Question 6: What happens if you remove the ReLu and Dropout layer from the GNN model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6c545-a914-4374-ad65-790c584d58da",
   "metadata": {},
   "source": [
    "### Answer 6: \n",
    "\n",
    "Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed95b03a-ea74-49c2-aa31-d8b187e9fd2f",
   "metadata": {},
   "source": [
    "## Question 7: Exchange the GCN layer with GATv2 and GraphSage. What gives you the best result?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67befa6-6050-4bbf-bc74-9721dde3fb6d",
   "metadata": {},
   "source": [
    "### Answer 7: \n",
    "\n",
    "Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a1e484-6c53-4f51-9626-ed4d94ecf1d4",
   "metadata": {},
   "source": [
    "# 4) GNN: Graph Property Prediction\n",
    "\n",
    "In this section we will create a graph neural network for graph property prediction (graph classification).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "97a50812-8bed-46e6-b6a2-b136c0eee808",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:47:42.254668Z",
     "start_time": "2024-06-16T22:47:23.713931Z"
    }
   },
   "source": [
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load the dataset\n",
    "dataset = PygGraphPropPredDataset(name='ogbg-molhiv')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "\n",
    "# Check task type\n",
    "print('Task type: {}'.format(dataset.task_type))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 3/3 [00:01<00:00,  2.43it/s]\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/hiv.zip\n",
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:02<00:00, 18055.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:08<00:00, 4745.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Device: cpu\n",
      "Task type: binary classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "a99ec7bf-a2a3-420e-89ba-56030f4f9bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:47:50.027836Z",
     "start_time": "2024-06-16T22:47:49.978273Z"
    }
   },
   "source": [
    "# Load the dataset splits into corresponding dataloaders\n",
    "# We will train the graph classification task on a batch of 32 graphs\n",
    "# Shuffle the order of graphs for training set\n",
    "train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False, num_workers=0)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/.conda/envs/graphml/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "618d4754-97ca-4ae4-b7b6-44f72d80a33b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:47:54.842276Z",
     "start_time": "2024-06-16T22:47:54.806432Z"
    }
   },
   "source": [
    "# Please do not change the args\n",
    "args = {\n",
    "    'device': device,\n",
    "    'num_layers': 5,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.5,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 30,\n",
    "}\n",
    "args"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'device': 'cpu',\n",
       " 'num_layers': 5,\n",
       " 'hidden_dim': 256,\n",
       " 'dropout': 0.5,\n",
       " 'lr': 0.001,\n",
       " 'epochs': 30}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "b87a5351-8bd3-40ff-beac-0a8fb2550fc5",
   "metadata": {},
   "source": [
    "## Graph Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1812e91-5491-4965-b00f-af587501f323",
   "metadata": {},
   "source": [
    "### Graph Mini-Batching\n",
    "Before diving into the actual model, we introduce the concept of mini-batching with graphs. In order to parallelize the processing of a mini-batch of graphs, PyG combines the graphs into a single disconnected graph data object (*torch_geometric.data.Batch*). *torch_geometric.data.Batch* inherits from *torch_geometric.data.Data* (introduced earlier) and contains an additional attribute called `batch`.\n",
    "\n",
    "The `batch` attribute is a vector mapping each node to the index of its corresponding graph within the mini-batch:\n",
    "\n",
    "    batch = [0, ..., 0, 1, ..., n - 2, n - 1, ..., n - 1]\n",
    "\n",
    "This attribute is crucial for associating which graph each node belongs to and can be used to e.g. average the node embeddings for each graph individually to compute graph level embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7001f37b-2b0d-4c3d-9741-485f460d08db",
   "metadata": {},
   "source": [
    "### Implemention\n",
    "Now, we have all of the tools to implement a GCN Graph Prediction model!  \n",
    "\n",
    "We will reuse the existing GCN model to generate `node_embeddings` and then use  `Global Pooling` over the nodes to create graph level embeddings that can be used to predict properties for the each graph. Remember that the `batch` attribute will be essential for performining Global Pooling over our mini-batch of graphs."
   ]
  },
  {
   "cell_type": "code",
   "id": "7e7ccdf0-3b99-4d9f-95c0-8b4ddbbbb67a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:48:43.894963Z",
     "start_time": "2024-06-16T22:48:43.838103Z"
    }
   },
   "source": [
    "from torch_geometric.nn import global_mean_pool\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "\n",
    "\n",
    "### GCN to predict graph property\n",
    "class GCN_Graph(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers, dropout):\n",
    "        super(GCN_Graph, self).__init__()\n",
    "\n",
    "        # Load encoders for Atoms in molecule graphs\n",
    "        self.node_encoder = AtomEncoder(hidden_dim)\n",
    "\n",
    "        # Node embedding model\n",
    "        # Note that the input_dim and output_dim are set to hidden_dim\n",
    "        self.gnn_node = GCN(hidden_dim, hidden_dim,\n",
    "                            hidden_dim, num_layers, dropout, return_embeds=True)\n",
    "\n",
    "        self.pool = None\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Initialize self.pool as a global mean pooling layer\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        # Output layer\n",
    "        self.linear = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.gnn_node.reset_parameters()\n",
    "        self.linear.reset_parameters()\n",
    "\n",
    "    # TODO: Implement a function that takes as input a\n",
    "    # mini-batch of graphs (torch_geometric.data.Batch) and\n",
    "    # returns the predicted graph property for each graph.\n",
    "    #\n",
    "    # NOTE: Since we are predicting graph level properties,\n",
    "    # your output will be a tensor with dimension equaling\n",
    "    # the number of graphs in the mini-batch\n",
    "    def forward(self, batched_data):\n",
    "        # Extract important attributes of our mini-batch\n",
    "        x, edge_index, batch = batched_data.x, batched_data.edge_index, batched_data.batch\n",
    "        embed = self.node_encoder(x)\n",
    "\n",
    "        ############# Your code here ############\n",
    "        ## Note:\n",
    "        ## 1. Construct node embeddings using existing GCN model\n",
    "        ## 2. Use the global pooling layer to aggregate features for each individual graph\n",
    "        ## For more information please refer to the documentation:\n",
    "        ## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\n",
    "        ## 3. Use a linear layer to predict each graph's property\n",
    "        embed = self.gnn_node(embed, edge_index)\n",
    "        pooled = self.pool(embed, batch)\n",
    "        out = self.linear(pooled)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "95e84fd1-7a9e-4f09-a48b-31daaf9cf4e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:48:07.257707Z",
     "start_time": "2024-06-16T22:48:07.216267Z"
    }
   },
   "source": [
    "# TODO: Implement a function that trains your model by\n",
    "# using the given optimizer and loss_fn.\n",
    "def train(model, device, data_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            ## ignore nan targets (unlabeled) when computing training loss.\n",
    "            is_labeled = batch.y == batch.y\n",
    "\n",
    "            ############# Your code here ############\n",
    "            ## Note:\n",
    "            ## 1. Zero grad the optimizer\n",
    "            ## 2. Feed the data into the model\n",
    "            ## 3. Use `is_labeled` mask to filter output and labels\n",
    "            ## 4. You may need to change the type of label to torch.float32\n",
    "            ## 5. Feed the output and label to the loss_fn\n",
    "\n",
    "            #########################################\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model.forward(batch)\n",
    "            out = out[is_labeled]\n",
    "            label = batch.y[is_labeled].float()\n",
    "            loss = loss_fn(out, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "882c0048-facb-466c-86e6-c40d7c2f90d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:48:14.635257Z",
     "start_time": "2024-06-16T22:48:14.564761Z"
    }
   },
   "source": [
    "# The evaluation function\n",
    "def eval(model, device, loader, evaluator, save_model_results=False, save_file=None):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "            y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim=0).numpy()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    if save_model_results:\n",
    "        print(\"Saving Model Predictions\")\n",
    "\n",
    "        # Create a pandas dataframe with a two columns\n",
    "        # y_pred | y_true\n",
    "        data = {}\n",
    "        data['y_pred'] = y_pred.reshape(-1)\n",
    "        data['y_true'] = y_true.reshape(-1)\n",
    "\n",
    "        df = pd.DataFrame(data=data)\n",
    "        # Save to csv\n",
    "        df.to_csv('ogbg-molhiv_graph_' + save_file + '.csv', sep=',', index=False)\n",
    "\n",
    "    return evaluator.eval(input_dict)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "7d3bd662-8aa8-45d2-b129-060f8a4762fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:48:49.453883Z",
     "start_time": "2024-06-16T22:48:49.382372Z"
    }
   },
   "source": [
    "model = GCN_Graph(args['hidden_dim'],\n",
    "                  dataset.num_tasks, args['num_layers'],\n",
    "                  args['dropout']).to(device)\n",
    "evaluator = Evaluator(name='ogbg-molhiv')"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "78a276c5-f32e-4490-a9d2-a1118f0d9973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T22:59:01.164363Z",
     "start_time": "2024-06-16T22:48:55.843050Z"
    }
   },
   "source": [
    "# Please do not change these args\n",
    "# Training should take <10min using GPU runtime\n",
    "import copy\n",
    "\n",
    "model.reset_parameters()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(1, 1 + args[\"epochs\"]):\n",
    "    print('Training...')\n",
    "    loss = train(model, device, train_loader, optimizer, loss_fn)\n",
    "\n",
    "    print('Evaluating...')\n",
    "    train_result = eval(model, device, train_loader, evaluator)\n",
    "    val_result = eval(model, device, valid_loader, evaluator)\n",
    "    test_result = eval(model, device, test_loader, evaluator)\n",
    "\n",
    "    train_acc, valid_acc, test_acc = train_result[dataset.eval_metric], val_result[dataset.eval_metric], test_result[\n",
    "        dataset.eval_metric]\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "    print(f'Epoch: {epoch:02d}, '\n",
    "          f'Loss: {loss:.4f}, '\n",
    "          f'Train: {100 * train_acc:.2f}%, '\n",
    "          f'Valid: {100 * valid_acc:.2f}% '\n",
    "          f'Test: {100 * test_acc:.2f}%')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a0b46aeb78448b48517eac77f640f77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7301c7d00e6b44c6bf6a4791e6cc57c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb6663848e9948a198d3e44aa69ac43e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e0dc55796c443a585de45bac5fa76fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.0330, Train: 72.25%, Valid: 67.24% Test: 68.34%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46f04cdcf5934331adc51e0187ba42fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9dab5f2f20f4004a4861f6ab1d30e86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61cb1bedfa704abfbfa6c60271325598"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "079e37d7e40e42e0bc290b056b4b0294"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Loss: 0.0368, Train: 75.60%, Valid: 72.45% Test: 70.51%\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4d6164d1df04639b6947afa262ce547"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m]):\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 15\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEvaluating...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     18\u001B[0m     train_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(model, device, train_loader, evaluator)\n",
      "Cell \u001B[0;32mIn[31], line 26\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, device, data_loader, optimizer, loss_fn)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m############# Your code here ############\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m## Note:\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m## 1. Zero grad the optimizer\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     22\u001B[0m \n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m#########################################\u001B[39;00m\n\u001B[1;32m     25\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 26\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m out \u001B[38;5;241m=\u001B[39m out[is_labeled]\n\u001B[1;32m     28\u001B[0m label \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39my[is_labeled]\u001B[38;5;241m.\u001B[39mfloat()\n",
      "Cell \u001B[0;32mIn[34], line 55\u001B[0m, in \u001B[0;36mGCN_Graph.forward\u001B[0;34m(self, batched_data)\u001B[0m\n\u001B[1;32m     46\u001B[0m embed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_encoder(x)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m############# Your code here ############\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m## Note:\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m## 1. Construct node embeddings using existing GCN model\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m## https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#global-pooling-layers\u001B[39;00m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m## 3. Use a linear layer to predict each graph's property\u001B[39;00m\n\u001B[0;32m---> 55\u001B[0m embed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgnn_node\u001B[49m\u001B[43m(\u001B[49m\u001B[43membed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m pooled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool(embed, batch)\n\u001B[1;32m     57\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear(pooled)\n",
      "File \u001B[0;32m~/.conda/envs/graphml/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/graphml/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[11], line 70\u001B[0m, in \u001B[0;36mGCN.forward\u001B[0;34m(self, x, edge_index)\u001B[0m\n\u001B[1;32m     68\u001B[0m     norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbns[i](conv_out)\n\u001B[1;32m     69\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(norm)\n\u001B[0;32m---> 70\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_embeds:\n\u001B[1;32m     73\u001B[0m     out \u001B[38;5;241m=\u001B[39m x\n",
      "File \u001B[0;32m~/.conda/envs/graphml/lib/python3.10/site-packages/torch/nn/functional.py:1295\u001B[0m, in \u001B[0;36mdropout\u001B[0;34m(input, p, training, inplace)\u001B[0m\n\u001B[1;32m   1293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m p \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdropout probability has to be between 0 and 1, but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1295\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _VF\u001B[38;5;241m.\u001B[39mdropout_(\u001B[38;5;28minput\u001B[39m, p, training) \u001B[38;5;28;01mif\u001B[39;00m inplace \u001B[38;5;28;01melse\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "2752b899-6137-4dce-bd49-061e419ab6e4",
   "metadata": {},
   "source": [
    "## Question 8: What are your `best_model` validation and test ROC-AUC scores?\n",
    "\n",
    "Run the cell below to see the results of your best of model and save your model's predictions over the validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd3494-b2f6-4810-9736-394ec103199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = eval(best_model, device, train_loader, evaluator)[dataset.eval_metric]\n",
    "valid_acc = eval(best_model, device, valid_loader, evaluator, save_model_results=False, save_file=\"valid\")[\n",
    "    dataset.eval_metric]\n",
    "test_acc = eval(best_model, device, test_loader, evaluator, save_model_results=False, save_file=\"test\")[\n",
    "    dataset.eval_metric]\n",
    "\n",
    "print(f'Best model: '\n",
    "      f'Train: {100 * train_acc:.2f}%, '\n",
    "      f'Valid: {100 * valid_acc:.2f}% '\n",
    "      f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98e0e93-2d66-478c-ac2a-3661a31c4c73",
   "metadata": {},
   "source": [
    "### Answer 8:\n",
    "\n",
    "Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4316b944-5d4a-4b83-a579-dc2e6f0e9df6",
   "metadata": {},
   "source": [
    "## Question 9: What is the role of `torch.nn.Linear` in the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d34ef6-f2b3-4271-b893-a6c460c67f11",
   "metadata": {},
   "source": [
    "### Answer 9:\n",
    "\n",
    "Your answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
